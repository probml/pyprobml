{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b18641eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of a Gaussian Process Regression with multiple local minima\n",
    "# in the marginal log-likelihood as a function of the hyperparameters\n",
    "# Based on: https://github.com/probml/pmtk3/blob/master/demos/gprDemoMarglik.m\n",
    "# Authors: Drishti Patel & Gerardo Durán-Martín\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "try:\n",
    "    import probml_utils as pml\n",
    "except ModuleNotFoundError:\n",
    "    %pip install -qq git+https://github.com/probml/probml-utils.git\n",
    "    import probml_utils as pml\n",
    "from numpy.linalg import inv, slogdet\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "\n",
    "def k(u, v, sigma_f, l=1):\n",
    "    return sigma_f**2 * np.exp(-((u - v) ** 2) / (2 * l**2))\n",
    "\n",
    "\n",
    "def gp_predictive_post(xstar, x, y, k, sigma_y, *args, **kwargs):\n",
    "    \"\"\"\n",
    "    Compute predictive distribution of a 1D-Gaussian Process for\n",
    "    regression\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    xstar: array(nt, 1)\n",
    "        Values to perform inference on\n",
    "    x: array(n, 1)\n",
    "        Training independent variables\n",
    "    y: array(n, 1)\n",
    "        Training dependent variables\n",
    "    k: function\n",
    "        Kernel function to evaluate the GP\n",
    "    sigma_y: float\n",
    "        data-noise term\n",
    "    *args: additional arguments of k\n",
    "    **kwargs: additional keyword-arguments of k\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    * array(nt, 1):\n",
    "        Array of predicted (mean) values\n",
    "    * array(nt, nt):\n",
    "        Posterior covariance matrix\n",
    "    \"\"\"\n",
    "    n, _ = x.shape\n",
    "    kstar = k(x, xstar.T, *args, **kwargs)\n",
    "    Kxx = k(x, x.T, *args) + sigma_y**2 * np.eye(n)\n",
    "    kxx_star = k(xstar, xstar.T, *args, **kwargs)\n",
    "    Kxx_inv = inv(Kxx)\n",
    "    ystar = kstar.T @ Kxx_inv @ y\n",
    "    Sigma_post = kxx_star - kstar.T @ Kxx_inv @ kstar\n",
    "\n",
    "    return ystar, Sigma_post\n",
    "\n",
    "\n",
    "def log_likelihood(x, y, sigma_f, l, sigma_y):\n",
    "    \"\"\"\n",
    "    Compute marginal log-likelihood of a regression GP\n",
    "    with rbf kernel\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    x: array(n, 1)\n",
    "        Training independent variables\n",
    "    y: array(n, 1)\n",
    "        Training dependent variables\n",
    "    sigma_f: float\n",
    "        Vertical-scale parameter\n",
    "    l: float\n",
    "        Horizontal-scale parameter\n",
    "    sigma_y: float\n",
    "        data noise\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    * float:\n",
    "        Marginal log-likelihood as the specified hyperparameters\n",
    "    \"\"\"\n",
    "    n, _ = x.shape\n",
    "    x = x / np.exp(l)\n",
    "    Kxx = k(x, x.T, sigma_f) + np.exp(2 * sigma_y) * np.eye(n)\n",
    "    _, DKxx = slogdet(Kxx)\n",
    "    l = -1 / 2 * (y.T @ inv(Kxx) @ y + DKxx + n * np.log(2 * np.pi))\n",
    "    return l.item()\n",
    "\n",
    "\n",
    "def plot_gp_pred(x, y, xstar, k, sigma_f, l, sigma_y, ax):\n",
    "    ystar, Sigma_post = gp_predictive_post(xstar, x, y, k, sigma_y, sigma_f, l)\n",
    "    upper_bound = ystar.ravel() + 2 * np.sqrt(np.diag(Sigma_post))\n",
    "    lower_bound = ystar.ravel() - 2 * np.sqrt(np.diag(Sigma_post))\n",
    "    ax.scatter(x, y, marker=\"+\", s=100, c=\"black\")\n",
    "    ax.plot(xstar, ystar, c=\"black\")\n",
    "    ax.fill_between(xstar.ravel(), lower_bound, upper_bound, color=\"tab:gray\", alpha=0.3, edgecolor=\"none\")\n",
    "    ax.set_xlim(-7.5, 7.5)\n",
    "    ax.set_ylim(-2, 2.5)\n",
    "\n",
    "\n",
    "def plot_marginal_likelihood_surface(x, y, sigma_f, l_space, sigma_y_space, ax, levels=None):\n",
    "    P = np.stack(np.meshgrid(l_space, sigma_y_space), axis=0)\n",
    "    Z = np.apply_along_axis(lambda p: log_likelihood(x, y, sigma_f, *p), 0, P)\n",
    "    ax.contour(*np.exp(P), Z, levels=levels)\n",
    "    ax.set_xlabel(\"characteristic length scale\")\n",
    "    ax.set_ylabel(\"noise standard deviation\")\n",
    "    ax.set_xscale(\"log\")\n",
    "    ax.set_yscale(\"log\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    plt.rcParams[\"axes.spines.right\"] = False\n",
    "    plt.rcParams[\"axes.spines.top\"] = False\n",
    "    sigma_f = 1.0\n",
    "    x = np.array([-1.3089, 6.7612, 1.0553, -1.1734, -2.9339, 7.2530, -6.5843])[:, None]\n",
    "    y = np.array([1.6218, 1.8558, 0.4102, 1.2526, -0.0133, 1.6380, 0.2189])[:, None]\n",
    "    xstar = np.linspace(-7.5, 7.5, 201)\n",
    "\n",
    "    ngrid = 41\n",
    "    l_space = np.linspace(np.log(0.5), np.log(80), ngrid)\n",
    "    sigma_y_space = np.linspace(np.log(0.03), np.log(3), ngrid)\n",
    "    P = np.stack(np.meshgrid(l_space, sigma_y_space), axis=0)\n",
    "    configs = [(1.0, 0.2), (10, 0.8)]\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    plot_gp_pred(x, y, xstar, k, sigma_f, *configs[0], ax)\n",
    "    pml.savefig(\"gpr_config0.pdf\")\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    plot_gp_pred(x, y, xstar, k, sigma_f, *configs[1], ax)\n",
    "    pml.savefig(\"gpr_config1.pdf\")\n",
    "\n",
    "    ngrid = 41\n",
    "    w01 = np.array([np.log(1), np.log(0.1)])\n",
    "    w02 = np.array([np.log(10), np.log(0.8)])\n",
    "    s0 = minimize(lambda p: -log_likelihood(x, y, sigma_f, *p), w01)\n",
    "    s1 = minimize(lambda p: -log_likelihood(x, y, sigma_f, *p), w02)\n",
    "    levels = -np.array([8.3, 8.5, 8.9, 9.3, 9.8, 11.5, 15])[::-1]\n",
    "    l_space = np.linspace(np.log(0.5), np.log(80), ngrid)\n",
    "    sigma_y_space = np.linspace(np.log(0.03), np.log(3), ngrid)\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    plot_marginal_likelihood_surface(x, y, sigma_f, l_space, sigma_y_space, ax, levels=levels)\n",
    "    plt.scatter(*np.exp(s0.x), marker=\"+\", s=100, c=\"tab:blue\")\n",
    "    plt.scatter(*np.exp(s1.x), marker=\"+\", s=100, c=\"tab:blue\")\n",
    "    pml.savefig(\"gpr_marginal_likelihood.pdf\")\n",
    "\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
