{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "opt_flax.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/probml/pyprobml/blob/master/book1/supplements/opt_flax.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b520E1nCIBHc"
      },
      "source": [
        "# Optimization using Flax\n",
        "\n",
        "\n",
        "[Flax](https://colab.research.google.com/giathub/probml/pyprobml/blob/master/book1/mlp/flax_intro.ipynb) is a JAX library for creating deep neural networks. It also has a simple optimization library built in.\n",
        "Below we show how to fit a multi-class logistic regression model using flax. \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UeuOgABaIENZ"
      },
      "source": [
        "import sklearn\n",
        "import scipy\n",
        "import scipy.optimize\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import itertools\n",
        "import time\n",
        "from functools import partial\n",
        "import os\n",
        "\n",
        "import numpy as np\n",
        "#np.set_printoptions(precision=3)\n",
        "np.set_printoptions(formatter={'float': lambda x: \"{0:0.5f}\".format(x)})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TNQHpyKLIx_P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b2e9b02d-bbad-4672-b6d2-8881f558b8b5"
      },
      "source": [
        "\n",
        "import jax\n",
        "import jax.numpy as jnp\n",
        "\n",
        "from jax.scipy.special import logsumexp\n",
        "from jax import grad, hessian, jacfwd, jacrev, jit, vmap\n",
        "print(\"jax version {}\".format(jax.__version__))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "jax version 0.2.7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RUICitLqjkrR"
      },
      "source": [
        "## Import code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HHI0RPrPblpY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "72d1fffb-7252-4681-d83d-1af3b83e3790"
      },
      "source": [
        "# Install Flax at head:\n",
        "!pip install --upgrade -q git+https://github.com/google/flax.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  Building wheel for flax (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jyv9ODiCf_aH"
      },
      "source": [
        "import flax\n",
        "from flax.core import freeze, unfreeze\n",
        "from flax import linen as nn\n",
        "from flax import optim\n",
        "\n",
        "from jax.config import config\n",
        "config.enable_omnistaging() # Linen requires enabling omnistaging"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pBzM5HwiiuM6",
        "outputId": "28028867-9e59-4c2f-df22-17c8a6a3675c"
      },
      "source": [
        "# Book code\n",
        "!git clone https://github.com/probml/pyprobml"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'pyprobml'...\n",
            "remote: Enumerating objects: 165, done.\u001b[K\n",
            "remote: Counting objects: 100% (165/165), done.\u001b[K\n",
            "remote: Compressing objects: 100% (113/113), done.\u001b[K\n",
            "remote: Total 5880 (delta 99), reused 89 (delta 51), pack-reused 5715\u001b[K\n",
            "Receiving objects: 100% (5880/5880), 200.88 MiB | 31.76 MiB/s, done.\n",
            "Resolving deltas: 100% (3347/3347), done.\n",
            "Checking out files: 100% (484/484), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4SMa9njai3Qt",
        "outputId": "2e816ef5-a5d2-4cd8-d8a6-04a334315ca5"
      },
      "source": [
        "\n",
        "\n",
        "import pyprobml.scripts.fit_flax as ff\n",
        "\n",
        "ff.test()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "testing fit-flax\n",
            "train step: 0, loss: 2.5385, accuracy: 0.00\n",
            "train step: 1, loss: 2.3316, accuracy: 0.00\n",
            "FrozenDict({\n",
            "    Dense_0: {\n",
            "        bias: DeviceArray([-0.07041515,  0.02852547,  0.02282   ,  0.02621041,\n",
            "                      0.04047536,  0.0282678 ,  0.02441146,  0.0334954 ,\n",
            "                     -0.16449487,  0.03070411], dtype=float32),\n",
            "        kernel: DeviceArray([[-1.3670444e-01,  3.4958541e-02, -7.1266890e-03,\n",
            "                       2.5135964e-02,  2.7813643e-02,  5.0281063e-03,\n",
            "                       2.9270068e-02,  3.3206850e-02,  7.8319311e-03,\n",
            "                      -1.9413888e-02],\n",
            "                     [ 2.3842663e-02, -1.4299959e-02,  6.5577030e-04,\n",
            "                      -6.1702281e-03, -1.8243194e-02, -3.5261810e-03,\n",
            "                      -9.2503726e-03, -7.1800947e-03,  2.8626800e-02,\n",
            "                       5.5447742e-03],\n",
            "                     [ 1.2182933e-01, -1.1020064e-02,  6.6978633e-03,\n",
            "                      -1.8483013e-02,  7.7033639e-03,  1.0741353e-03,\n",
            "                      -1.6080946e-02, -2.6806772e-02, -7.5067461e-02,\n",
            "                       1.0153547e-02],\n",
            "                     [-6.5444291e-02, -1.2274325e-02, -2.4778858e-02,\n",
            "                      -2.5078654e-03, -4.0774703e-02, -2.3661405e-02,\n",
            "                      -3.6602318e-03,  3.6180019e-05,  2.0730698e-01,\n",
            "                      -3.4241520e-02],\n",
            "                     [-8.0969959e-02,  7.9388879e-03,  3.2993864e-02,\n",
            "                       2.8362900e-02,  8.9270771e-03,  3.1862110e-02,\n",
            "                       1.6838670e-02,  3.9151609e-02, -1.4136736e-01,\n",
            "                       5.6262240e-02]], dtype=float32),\n",
            "    },\n",
            "})\n",
            "test passed\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YWp-tBzfdXHe"
      },
      "source": [
        "Now we show the source code for the fitting function in the file editor on the RHS.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "eT5_wY4SdacY",
        "outputId": "329d4db2-b8c4-462c-8c3b-a87817b50d0c"
      },
      "source": [
        "from google.colab import files\n",
        "files.view('pyprobml/scripts/fit_flax.py')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "      ((filepath) => {{\n",
              "        if (!google.colab.kernel.accessAllowed) {{\n",
              "          return;\n",
              "        }}\n",
              "        google.colab.files.view(filepath);\n",
              "      }})(\"/content/pyprobml/scripts/fit_flax.py\")"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wHnVMv3zjnt3"
      },
      "source": [
        "## Data\n",
        "\n",
        "We use the [tensorflow datasets](https://colab.research.google.com/github/probml/pyprobml/blob/master/book1/intro/datasets.ipynb) library to make it easy to create minibatches.\n",
        "\n",
        "We switch to the multi-class version of Iris."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0a-tDJOfjIf7",
        "outputId": "2e44c3f8-aace-49e2-9acc-ed8df501e993"
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "import sklearn\n",
        "import sklearn.datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "def get_datasets_iris():\n",
        "  iris = sklearn.datasets.load_iris()\n",
        "  X = iris[\"data\"]\n",
        "  y = iris[\"target\"] \n",
        "  N, D = X.shape # 150, 4\n",
        "  X_train, X_test, y_train, y_test = train_test_split(\n",
        "          X, y, test_size=0.33, random_state=42)\n",
        "  train_data = {'X': X_train, 'y': y_train}\n",
        "  test_data = {'X': X_test, 'y': y_test}\n",
        "  return train_data, test_data\n",
        "\n",
        "def load_dataset_iris(split, batch_size=None):\n",
        "  train_ds, test_ds = get_datasets_iris()\n",
        "  if split == tfds.Split.TRAIN:\n",
        "    ds = tf.data.Dataset.from_tensor_slices({\"X\": train_ds[\"X\"], \"y\": train_ds[\"y\"]})\n",
        "  elif split == tfds.Split.TEST:\n",
        "    ds = tf.data.Dataset.from_tensor_slices({\"X\": test_ds[\"X\"], \"y\": test_ds[\"y\"]})\n",
        "  if batch_size is not None:\n",
        "    ds = ds.shuffle(buffer_size=batch_size)\n",
        "    ds = ds.batch(batch_size)\n",
        "  else:\n",
        "    N = len(train_ds['X'])\n",
        "    ds = ds.batch(N)\n",
        "  ds = ds.prefetch(buffer_size=5)\n",
        "  ds = ds.repeat() # make infinite stream of data\n",
        "  return iter(tfds.as_numpy(ds)) # python iterator\n",
        "\n",
        "\n",
        "batch_size = 30\n",
        "train_ds = load_dataset_iris(tfds.Split.TRAIN, batch_size)\n",
        "batch = next(train_ds)\n",
        "print(batch['X'].shape)\n",
        "print(batch['y'].shape)\n",
        "\n",
        "test_ds = load_dataset_iris(tfds.Split.TEST, None) # load full test set\n",
        "batch = next(test_ds)\n",
        "print(batch['X'].shape)\n",
        "print(batch['y'].shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(30, 4)\n",
            "(30,)\n",
            "(50, 4)\n",
            "(50,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VrzcCrmsjpi-"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P5JQ3iovjqGS"
      },
      "source": [
        "class Model(nn.Module):\n",
        "  nhidden: int\n",
        "  nclasses: int\n",
        "\n",
        "  @nn.compact\n",
        "  def __call__(self, x):\n",
        "    if self.nhidden > 0:\n",
        "      x = nn.Dense(self.nhidden)(x)\n",
        "      x = nn.relu(x)\n",
        "    x = nn.Dense(self.nclasses)(x)\n",
        "    x = nn.log_softmax(x)\n",
        "    return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bwuGK8GJjxy_"
      },
      "source": [
        "## Training loop\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 497
        },
        "id": "fN29jn7XjzG1",
        "outputId": "6bb61444-f4e8-48e4-d0f1-767459a98cf8"
      },
      "source": [
        "from flax import optim\n",
        "\n",
        "make_optimizer = optim.Momentum(learning_rate=0.1, beta=0.9)\n",
        "\n",
        "model = Model(nhidden = 0, nclasses=3) # no hidden units ie logistic regression\n",
        "\n",
        "batch_size = 100 # 30 # full batch training\n",
        "train_ds = load_dataset_iris(tfds.Split.TRAIN, batch_size)\n",
        "test_ds = load_dataset_iris(tfds.Split.TEST, batch_size)\n",
        "\n",
        "rng = jax.random.PRNGKey(0)\n",
        "num_steps = 200\n",
        "\n",
        "  \n",
        "params, history =  ff.fit_model(\n",
        "    model, rng, num_steps, train_ds, test_ds, print_every=20)\n",
        "\n",
        "display(history)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train step: 0, loss: 4.2830, accuracy: 0.35\n",
            "train step: 20, loss: 0.9130, accuracy: 0.65\n",
            "train step: 40, loss: 0.1380, accuracy: 0.96\n",
            "train step: 60, loss: 0.1236, accuracy: 0.96\n",
            "train step: 80, loss: 0.1094, accuracy: 0.98\n",
            "train step: 100, loss: 0.1041, accuracy: 0.98\n",
            "train step: 120, loss: 0.1002, accuracy: 0.98\n",
            "train step: 140, loss: 0.0969, accuracy: 0.98\n",
            "train step: 160, loss: 0.0942, accuracy: 0.99\n",
            "train step: 180, loss: 0.0917, accuracy: 0.99\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>train_loss</th>\n",
              "      <th>train_accuracy</th>\n",
              "      <th>test_loss</th>\n",
              "      <th>test_accuracy</th>\n",
              "      <th>step</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4.2829556</td>\n",
              "      <td>0.35</td>\n",
              "      <td>1.8996174</td>\n",
              "      <td>0.28</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.9129939</td>\n",
              "      <td>0.65</td>\n",
              "      <td>0.2596313</td>\n",
              "      <td>0.82</td>\n",
              "      <td>20.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.13796234</td>\n",
              "      <td>0.96</td>\n",
              "      <td>0.11790658</td>\n",
              "      <td>0.96</td>\n",
              "      <td>40.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.123637825</td>\n",
              "      <td>0.96</td>\n",
              "      <td>0.086329155</td>\n",
              "      <td>1.0</td>\n",
              "      <td>60.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.109449916</td>\n",
              "      <td>0.97999996</td>\n",
              "      <td>0.089117624</td>\n",
              "      <td>1.0</td>\n",
              "      <td>80.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.10408671</td>\n",
              "      <td>0.97999996</td>\n",
              "      <td>0.08658601</td>\n",
              "      <td>1.0</td>\n",
              "      <td>100.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.10017303</td>\n",
              "      <td>0.97999996</td>\n",
              "      <td>0.08438768</td>\n",
              "      <td>1.0</td>\n",
              "      <td>120.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.09693686</td>\n",
              "      <td>0.97999996</td>\n",
              "      <td>0.0829268</td>\n",
              "      <td>0.97999996</td>\n",
              "      <td>140.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.094163276</td>\n",
              "      <td>0.98999995</td>\n",
              "      <td>0.081612006</td>\n",
              "      <td>0.97999996</td>\n",
              "      <td>160.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.091744594</td>\n",
              "      <td>0.98999995</td>\n",
              "      <td>0.08027973</td>\n",
              "      <td>0.97999996</td>\n",
              "      <td>180.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    train_loss train_accuracy    test_loss test_accuracy   step\n",
              "0    4.2829556           0.35    1.8996174          0.28    0.0\n",
              "1    0.9129939           0.65    0.2596313          0.82   20.0\n",
              "2   0.13796234           0.96   0.11790658          0.96   40.0\n",
              "3  0.123637825           0.96  0.086329155           1.0   60.0\n",
              "4  0.109449916     0.97999996  0.089117624           1.0   80.0\n",
              "5   0.10408671     0.97999996   0.08658601           1.0  100.0\n",
              "6   0.10017303     0.97999996   0.08438768           1.0  120.0\n",
              "7   0.09693686     0.97999996    0.0829268    0.97999996  140.0\n",
              "8  0.094163276     0.98999995  0.081612006    0.97999996  160.0\n",
              "9  0.091744594     0.98999995   0.08027973    0.97999996  180.0"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 278
        },
        "id": "-NzU_wMAkut-",
        "outputId": "1f95b91a-4b7e-41a8-a3dc-41e48c54a0aa"
      },
      "source": [
        "plt.figure()\n",
        "plt.plot(history['step'], history['test_accuracy'], 'o-', label='test accuracy')\n",
        "plt.xlabel('num. minibatches')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "um91hW0ikzfe"
      },
      "source": [
        "## Compare to sklearn\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1XPa5V5hk0vd",
        "outputId": "7a319aba-817e-4371-ec72-ed42bb3c1a1c"
      },
      "source": [
        "train_ds, test_ds = get_datasets_iris()\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# We set C to a large number to turn off regularization.\n",
        "log_reg = LogisticRegression(solver=\"lbfgs\", C=1e3, fit_intercept=True)\n",
        "log_reg.fit(train_ds['X'], train_ds['y'])\n",
        "\n",
        "w_sklearn = np.ravel(log_reg.coef_)\n",
        "print(w_sklearn)\n",
        "b_sklearn = np.ravel(log_reg.intercept_)\n",
        "print(b_sklearn)\n",
        "\n",
        "yprob_sklearn = log_reg.predict_proba(test_ds['X'])\n",
        "print(yprob_sklearn.shape)\n",
        "print(yprob_sklearn[:10,:])\n",
        "\n",
        "\n",
        "ypred_sklearn = jnp.argmax(yprob_sklearn, axis=-1)\n",
        "print(ypred_sklearn.shape)\n",
        "print(ypred_sklearn[:10])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[5.69473 8.89993 -12.90385 -6.59589 -1.40077 1.88896 0.08464 -14.39687\n",
            " -4.29397 -10.78889 12.81921 20.99277]\n",
            "[3.97582 32.52712 -36.50294]\n",
            "(50, 3)\n",
            "[[0.00000 1.00000 0.00000]\n",
            " [1.00000 0.00000 0.00000]\n",
            " [0.00000 0.00000 1.00000]\n",
            " [0.00000 0.99999 0.00000]\n",
            " [0.00001 0.99999 0.00000]\n",
            " [1.00000 0.00000 0.00000]\n",
            " [0.00605 0.99395 0.00000]\n",
            " [0.00000 0.00000 1.00000]\n",
            " [0.00000 0.98867 0.01133]\n",
            " [0.00006 0.99994 0.00000]]\n",
            "(50,)\n",
            "[1 0 2 1 1 0 1 2 1 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I_QxgKCilBrn",
        "outputId": "8b3918cb-feca-40d7-d4fd-6aa23aea3a99"
      },
      "source": [
        "# Flax version\n",
        "print(params)\n",
        "\n",
        "train_ds, test_ds = get_datasets_iris()\n",
        "Xtest = test_ds['X']\n",
        "logits = model.apply({'params': params}, Xtest)\n",
        "yprob = nn.softmax(logits)\n",
        "print(yprob.shape)\n",
        "print(yprob[:10,:])\n",
        "print(np.allclose(yprob_sklearn, yprob, atol=1e-0)) # very loose numerical tolerance\n",
        "\n",
        "ypred = jnp.argmax(yprob, axis=-1)\n",
        "print(ypred[:10])\n",
        "print(np.allclose(ypred_sklearn, ypred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "FrozenDict({\n",
            "    Dense_0: {\n",
            "        bias: DeviceArray([0.67322, 1.05858, -1.73180], dtype=float32),\n",
            "        kernel: DeviceArray([[1.13125, 0.95521, -2.30099],\n",
            "                     [2.86528, -0.09720, -3.41202],\n",
            "                     [-3.86220, -0.45856, 4.46158],\n",
            "                     [-1.57317, -1.24467, 3.70615]], dtype=float32),\n",
            "    },\n",
            "})\n",
            "(50, 3)\n",
            "[[0.00057 0.94575 0.05368]\n",
            " [0.99750 0.00250 0.00000]\n",
            " [0.00000 0.00014 0.99986]\n",
            " [0.00131 0.91360 0.08509]\n",
            " [0.00045 0.97463 0.02493]\n",
            " [0.99551 0.00449 0.00000]\n",
            " [0.02960 0.96893 0.00147]\n",
            " [0.00008 0.27976 0.72016]\n",
            " [0.00012 0.66911 0.33077]\n",
            " [0.00644 0.98950 0.00406]]\n",
            "True\n",
            "[1 0 2 1 1 0 1 2 1 1]\n",
            "True\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}