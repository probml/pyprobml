{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a9937d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Relevance network newsgroup\n",
    "# Author: Drishtii@\n",
    "# Based on:\n",
    "# https://github.com/probml/pmtk3/blob/master/demos/relevanceNetworkNewsgroupDemo.m\n",
    "\n",
    "#!pip install -qq pgmpy\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "try:\n",
    "    import networkx as nx\n",
    "except ModuleNotFoundError:\n",
    "    %pip install -qq networkx\n",
    "    import networkx as nx\n",
    "try:\n",
    "    from pgmpy.estimators import TreeSearch\n",
    "except ModuleNotFoundError:\n",
    "    %pip install -qq pgmpy\n",
    "    from pgmpy.estimators import TreeSearch\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "try:\n",
    "    import pydot\n",
    "except ModuleNotFoundError:\n",
    "    %pip install -qq pydot\n",
    "    import pydot\n",
    "from networkx.drawing.nx_pydot import graphviz_layout\n",
    "from IPython.display import Image, display\n",
    "\n",
    "try:\n",
    "    import probml_utils as pml\n",
    "except ModuleNotFoundError:\n",
    "    %pip install -qq git+https://github.com/probml/probml-utils.git\n",
    "    import probml_utils as pml\n",
    "from itertools import combinations\n",
    "\n",
    "try:\n",
    "    from tqdm import tqdm\n",
    "except ModuleNotFoundError:\n",
    "    %pip install -qq tqdm\n",
    "    from tqdm import tqdm\n",
    "from joblib import Parallel, delayed\n",
    "from sklearn.metrics import mutual_info_score\n",
    "\n",
    "newsgroups_train = fetch_20newsgroups(subset=\"train\")\n",
    "\n",
    "list_of_words = [\n",
    "    \"baseball\",\n",
    "    \"bible\",\n",
    "    \"case\",\n",
    "    \"course\",\n",
    "    \"evidence\",\n",
    "    \"children\",\n",
    "    \"mission\",\n",
    "    \"launch\",\n",
    "    \"files\",\n",
    "    \"games\",\n",
    "    \"league\",\n",
    "    \"nhl\",\n",
    "    \"fans\",\n",
    "    \"hockey\",\n",
    "    \"players\",\n",
    "    \"christian\",\n",
    "    \"fact\",\n",
    "    \"god\",\n",
    "    \"human\",\n",
    "    \"jews\",\n",
    "    \"war\",\n",
    "    \"president\",\n",
    "    \"law\",\n",
    "    \"orbit\",\n",
    "    \"shuttle\",\n",
    "    \"moon\",\n",
    "    \"program\",\n",
    "    \"version\",\n",
    "    \"graphics\",\n",
    "    \"video\",\n",
    "    \"israel\",\n",
    "    \"government\",\n",
    "    \"earth\",\n",
    "    \"gun\",\n",
    "    \"nasa\",\n",
    "    \"lunar\",\n",
    "    \"format\",\n",
    "    \"ftp\",\n",
    "    \"card\",\n",
    "    \"jesus\",\n",
    "    \"computer\",\n",
    "    \"science\",\n",
    "    \"religion\",\n",
    "    \"world\",\n",
    "    \"rights\",\n",
    "    \"solar\",\n",
    "    \"space\",\n",
    "    \"windows\",\n",
    "    \"state\",\n",
    "]\n",
    "\n",
    "count_vect = CountVectorizer(newsgroups_train.data, vocabulary=list_of_words)\n",
    "X_train_counts = count_vect.fit_transform(newsgroups_train.data)\n",
    "\n",
    "df_ = pd.DataFrame.sparse.from_spmatrix(X_train_counts, columns=list_of_words)\n",
    "\n",
    "n_jobs = 1\n",
    "edge_weights_fn = mutual_info_score\n",
    "data = df_\n",
    "pbar = combinations(df_.columns, 2)\n",
    "n_vars = len(df_.columns)\n",
    "\n",
    "vals = Parallel(n_jobs=n_jobs, prefer=\"threads\")(\n",
    "    delayed(edge_weights_fn)(data.loc[:, u], data.loc[:, v]) for u, v in pbar\n",
    ")\n",
    "weights = np.zeros((n_vars, n_vars))\n",
    "weights[np.triu_indices(n_vars, k=1)] = vals\n",
    "max = np.max(weights)\n",
    "twenty_percent_of_max = 0.2 * max\n",
    "\n",
    "# Considering edges whose mutual information is greater than or equal to 20% of the maximum pairwise MI\n",
    "final_weights = np.zeros((n_vars, n_vars))\n",
    "for i in range(n_vars):\n",
    "    for j in range(n_vars):\n",
    "        if weights[i, j] > twenty_percent_of_max:\n",
    "            final_weights[i, j] = weights[i, j]\n",
    "\n",
    "G = nx.from_numpy_array(final_weights, create_using=nx.MultiGraph)\n",
    "G.remove_nodes_from(list(nx.isolates(G)))\n",
    "\n",
    "keys = list(G.nodes)\n",
    "values = list_of_words\n",
    "dictionary = dict(zip(keys, values))\n",
    "G = nx.relabel_nodes(G, dictionary)\n",
    "\n",
    "\n",
    "def view_pydot(pdot):\n",
    "    plt = Image(pdot.create_png())\n",
    "    display(plt)\n",
    "\n",
    "\n",
    "p2 = nx.drawing.nx_pydot.to_pydot(G)\n",
    "view_pydot(p2)\n",
    "p2.write_png(\"../figures/relevance_network.png\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
