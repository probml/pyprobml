{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright 2021 Google LLC\n",
    "# Use of this source code is governed by an MIT-style\n",
    "# license that can be found in the LICENSE file or at\n",
    "# https://opensource.org/licenses/MIT.\n",
    "# Notebook authors: Kevin P. Murphy (murphyk@gmail.com)\n",
    "# and Mahmoud Soliman (mjs@aucegypt.edu)\n",
    "\n",
    "# This notebook reproduces figures for chapter 15 from the book\n",
    "# \"Probabilistic Machine Learning: An Introduction\"\n",
    "# by Kevin Murphy (MIT Press, 2021).\n",
    "# Book pdf is available from http://probml.ai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://opensource.org/licenses/MIT\" target=\"_parent\"><img src=\"https://img.shields.io/github/license/probml/pyprobml\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/probml/pyprobml/blob/master/book1/figures/chapter15_neural_networks_for_sequences_figures.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 15.1:<a name='15.1'></a> <a name='rnn'></a> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "  Recurrent neural network (RNN) for generating a variable length output sequence $\\mathbf  y _ 1:T $ given an optional fixed length input vector $\\mathbf  x $. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Click me to run setup { display-mode: \"form\" }\n",
    "try:\n",
    "  if PYPROBML_SETUP_ALREADY_RUN:\n",
    "    print('skipping setup')\n",
    "except:\n",
    "  PYPROBML_SETUP_ALREADY_RUN = True\n",
    "  print('running setup...')\n",
    "  !git clone https://github.com/probml/pyprobml /pyprobml &> /dev/null \n",
    "  %cd -q /pyprobml/scripts\n",
    "  import pyprobml_utils as pml\n",
    "  import colab_utils\n",
    "  import os\n",
    "  os.environ[\"PYPROBML\"] = \"..\" # one above current scripts directory\n",
    "  import google.colab \n",
    "  from google.colab.patches import cv2_imshow\n",
    "  %reload_ext autoreload \n",
    "  %autoreload 2\n",
    "  def show_image(img_path,size=None,ratio=None):\n",
    "      img = colab_utils.image_resize(img_path, size)\n",
    "      cv2_imshow(img)\n",
    "  print('finished!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(\"/pyprobml/book1/figures/images/Figure_15.1.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 15.2:<a name='15.2'></a> <a name='rnnTimeMachine'></a> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "  Example output of length 500 generated from a character level RNN when given the prefix ``the''. We use greedy decoding, in which the most likely character at each step is computed, and then fed back into the model. The model is trained on the book  \\em The Time Machine  by H. G. Wells. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To reproduce this figure, click the open in colab button: <a href=\"https://colab.research.google.com/github/https://colab.research.google.com/github/probml/pyprobml/blob/master/notebooks/rnn_torch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Click me to run setup { display-mode: \"form\" }\n",
    "try:\n",
    "  if PYPROBML_SETUP_ALREADY_RUN:\n",
    "    print('skipping setup')\n",
    "except:\n",
    "  PYPROBML_SETUP_ALREADY_RUN = True\n",
    "  print('running setup...')\n",
    "  !git clone https://github.com/probml/pyprobml /pyprobml &> /dev/null \n",
    "  %cd -q /pyprobml/scripts\n",
    "  import pyprobml_utils as pml\n",
    "  import colab_utils\n",
    "  import os\n",
    "  os.environ[\"PYPROBML\"] = \"..\" # one above current scripts directory\n",
    "  import google.colab \n",
    "  from google.colab.patches import cv2_imshow\n",
    "  %reload_ext autoreload \n",
    "  %autoreload 2\n",
    "  def show_image(img_path,size=None,ratio=None):\n",
    "      img = colab_utils.image_resize(img_path, size)\n",
    "      cv2_imshow(img)\n",
    "  print('finished!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 15.3:<a name='15.3'></a> <a name='imageCaptioning'></a> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "  Illustration of a CNN-RNN model for image captioning. The pink boxes labeled ``LSTM'' refer to a specific kind of RNN that we discuss in \\cref  sec:LSTM . The pink boxes labeled $W_ \\text  emb  $ refer to embedding matrices for the (sampled) one-hot tokens, so that the input to the model is a real-valued vector. From   https://bit.ly/2FKnqHm . Used with kind permission of Yunjey Choi. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Click me to run setup { display-mode: \"form\" }\n",
    "try:\n",
    "  if PYPROBML_SETUP_ALREADY_RUN:\n",
    "    print('skipping setup')\n",
    "except:\n",
    "  PYPROBML_SETUP_ALREADY_RUN = True\n",
    "  print('running setup...')\n",
    "  !git clone https://github.com/probml/pyprobml /pyprobml &> /dev/null \n",
    "  %cd -q /pyprobml/scripts\n",
    "  import pyprobml_utils as pml\n",
    "  import colab_utils\n",
    "  import os\n",
    "  os.environ[\"PYPROBML\"] = \"..\" # one above current scripts directory\n",
    "  import google.colab \n",
    "  from google.colab.patches import cv2_imshow\n",
    "  %reload_ext autoreload \n",
    "  %autoreload 2\n",
    "  def show_image(img_path,size=None,ratio=None):\n",
    "      img = colab_utils.image_resize(img_path, size)\n",
    "      cv2_imshow(img)\n",
    "  print('finished!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(\"/pyprobml/book1/figures/images/Figure_15.3.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 15.4:<a name='15.4'></a> <a name='rnnBiPool'></a> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "  (a) RNN for sequence classification. (b) Bi-directional RNN for sequence classification. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Click me to run setup { display-mode: \"form\" }\n",
    "try:\n",
    "  if PYPROBML_SETUP_ALREADY_RUN:\n",
    "    print('skipping setup')\n",
    "except:\n",
    "  PYPROBML_SETUP_ALREADY_RUN = True\n",
    "  print('running setup...')\n",
    "  !git clone https://github.com/probml/pyprobml /pyprobml &> /dev/null \n",
    "  %cd -q /pyprobml/scripts\n",
    "  import pyprobml_utils as pml\n",
    "  import colab_utils\n",
    "  import os\n",
    "  os.environ[\"PYPROBML\"] = \"..\" # one above current scripts directory\n",
    "  import google.colab \n",
    "  from google.colab.patches import cv2_imshow\n",
    "  %reload_ext autoreload \n",
    "  %autoreload 2\n",
    "  def show_image(img_path,size=None,ratio=None):\n",
    "      img = colab_utils.image_resize(img_path, size)\n",
    "      cv2_imshow(img)\n",
    "  print('finished!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(\"/pyprobml/book1/figures/images/Figure_15.4_A.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(\"/pyprobml/book1/figures/images/Figure_15.4_B.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 15.5:<a name='15.5'></a> <a name='biRNN'></a> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "  (a) RNN for transforming a sequence to another, aligned sequence. (b) Bi-directional RNN for the same task. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Click me to run setup { display-mode: \"form\" }\n",
    "try:\n",
    "  if PYPROBML_SETUP_ALREADY_RUN:\n",
    "    print('skipping setup')\n",
    "except:\n",
    "  PYPROBML_SETUP_ALREADY_RUN = True\n",
    "  print('running setup...')\n",
    "  !git clone https://github.com/probml/pyprobml /pyprobml &> /dev/null \n",
    "  %cd -q /pyprobml/scripts\n",
    "  import pyprobml_utils as pml\n",
    "  import colab_utils\n",
    "  import os\n",
    "  os.environ[\"PYPROBML\"] = \"..\" # one above current scripts directory\n",
    "  import google.colab \n",
    "  from google.colab.patches import cv2_imshow\n",
    "  %reload_ext autoreload \n",
    "  %autoreload 2\n",
    "  def show_image(img_path,size=None,ratio=None):\n",
    "      img = colab_utils.image_resize(img_path, size)\n",
    "      cv2_imshow(img)\n",
    "  print('finished!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(\"/pyprobml/book1/figures/images/Figure_15.5_A.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(\"/pyprobml/book1/figures/images/Figure_15.5_B.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 15.6:<a name='15.6'></a> <a name='deepRNN'></a> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "  Illustration of a deep RNN. Adapted from Figure 9.3.1 of <a href='#dive'>[Zha+20]</a> . "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Click me to run setup { display-mode: \"form\" }\n",
    "try:\n",
    "  if PYPROBML_SETUP_ALREADY_RUN:\n",
    "    print('skipping setup')\n",
    "except:\n",
    "  PYPROBML_SETUP_ALREADY_RUN = True\n",
    "  print('running setup...')\n",
    "  !git clone https://github.com/probml/pyprobml /pyprobml &> /dev/null \n",
    "  %cd -q /pyprobml/scripts\n",
    "  import pyprobml_utils as pml\n",
    "  import colab_utils\n",
    "  import os\n",
    "  os.environ[\"PYPROBML\"] = \"..\" # one above current scripts directory\n",
    "  import google.colab \n",
    "  from google.colab.patches import cv2_imshow\n",
    "  %reload_ext autoreload \n",
    "  %autoreload 2\n",
    "  def show_image(img_path,size=None,ratio=None):\n",
    "      img = colab_utils.image_resize(img_path, size)\n",
    "      cv2_imshow(img)\n",
    "  print('finished!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(\"/pyprobml/book1/figures/images/Figure_15.6.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 15.7:<a name='15.7'></a> <a name='seq2seq'></a> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "  Encoder-decoder RNN architecture for mapping sequence $\\mathbf  x _ 1:T $ to sequence $\\mathbf  y _ 1:T' $. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Click me to run setup { display-mode: \"form\" }\n",
    "try:\n",
    "  if PYPROBML_SETUP_ALREADY_RUN:\n",
    "    print('skipping setup')\n",
    "except:\n",
    "  PYPROBML_SETUP_ALREADY_RUN = True\n",
    "  print('running setup...')\n",
    "  !git clone https://github.com/probml/pyprobml /pyprobml &> /dev/null \n",
    "  %cd -q /pyprobml/scripts\n",
    "  import pyprobml_utils as pml\n",
    "  import colab_utils\n",
    "  import os\n",
    "  os.environ[\"PYPROBML\"] = \"..\" # one above current scripts directory\n",
    "  import google.colab \n",
    "  from google.colab.patches import cv2_imshow\n",
    "  %reload_ext autoreload \n",
    "  %autoreload 2\n",
    "  def show_image(img_path,size=None,ratio=None):\n",
    "      img = colab_utils.image_resize(img_path, size)\n",
    "      cv2_imshow(img)\n",
    "  print('finished!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(\"/pyprobml/book1/figures/images/Figure_15.7.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 15.8:<a name='15.8'></a> <a name='NMT'></a> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "  (a) Illustration of a seq2seq model for translating English to French. The - character represents the end of a sentence. From Figure 2.4 of <a href='#Luong2016thesis'>[Luo16]</a> . Used with kind permission of Minh-Thang Luong. (b) Illustration of greedy decoding. The most likely French word at each step is highlighted in green, and then fed in as input to the next step of the decoder. From Figure 2.5 of <a href='#Luong2016thesis'>[Luo16]</a> . Used with kind permission of Minh-Thang Luong. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Click me to run setup { display-mode: \"form\" }\n",
    "try:\n",
    "  if PYPROBML_SETUP_ALREADY_RUN:\n",
    "    print('skipping setup')\n",
    "except:\n",
    "  PYPROBML_SETUP_ALREADY_RUN = True\n",
    "  print('running setup...')\n",
    "  !git clone https://github.com/probml/pyprobml /pyprobml &> /dev/null \n",
    "  %cd -q /pyprobml/scripts\n",
    "  import pyprobml_utils as pml\n",
    "  import colab_utils\n",
    "  import os\n",
    "  os.environ[\"PYPROBML\"] = \"..\" # one above current scripts directory\n",
    "  import google.colab \n",
    "  from google.colab.patches import cv2_imshow\n",
    "  %reload_ext autoreload \n",
    "  %autoreload 2\n",
    "  def show_image(img_path,size=None,ratio=None):\n",
    "      img = colab_utils.image_resize(img_path, size)\n",
    "      cv2_imshow(img)\n",
    "  print('finished!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(\"/pyprobml/book1/figures/images/Figure_15.8_A.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(\"/pyprobml/book1/figures/images/Figure_15.8_B.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 15.9:<a name='15.9'></a> <a name='BPTT'></a> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "  An RNN unrolled (vertically) for 3 time steps, with the target output sequence and loss node shown explicitly. From Figure 8.7.2 of <a href='#dive'>[Zha+20]</a> . Used with kind permission of Aston Zhang. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Click me to run setup { display-mode: \"form\" }\n",
    "try:\n",
    "  if PYPROBML_SETUP_ALREADY_RUN:\n",
    "    print('skipping setup')\n",
    "except:\n",
    "  PYPROBML_SETUP_ALREADY_RUN = True\n",
    "  print('running setup...')\n",
    "  !git clone https://github.com/probml/pyprobml /pyprobml &> /dev/null \n",
    "  %cd -q /pyprobml/scripts\n",
    "  import pyprobml_utils as pml\n",
    "  import colab_utils\n",
    "  import os\n",
    "  os.environ[\"PYPROBML\"] = \"..\" # one above current scripts directory\n",
    "  import google.colab \n",
    "  from google.colab.patches import cv2_imshow\n",
    "  %reload_ext autoreload \n",
    "  %autoreload 2\n",
    "  def show_image(img_path,size=None,ratio=None):\n",
    "      img = colab_utils.image_resize(img_path, size)\n",
    "      cv2_imshow(img)\n",
    "  print('finished!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(\"/pyprobml/book1/figures/images/Figure_15.9.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 15.10:<a name='15.10'></a> <a name='GRU'></a> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "  Illustration of a GRU. Adapted from Figure 9.1.3 of <a href='#dive'>[Zha+20]</a> . "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Click me to run setup { display-mode: \"form\" }\n",
    "try:\n",
    "  if PYPROBML_SETUP_ALREADY_RUN:\n",
    "    print('skipping setup')\n",
    "except:\n",
    "  PYPROBML_SETUP_ALREADY_RUN = True\n",
    "  print('running setup...')\n",
    "  !git clone https://github.com/probml/pyprobml /pyprobml &> /dev/null \n",
    "  %cd -q /pyprobml/scripts\n",
    "  import pyprobml_utils as pml\n",
    "  import colab_utils\n",
    "  import os\n",
    "  os.environ[\"PYPROBML\"] = \"..\" # one above current scripts directory\n",
    "  import google.colab \n",
    "  from google.colab.patches import cv2_imshow\n",
    "  %reload_ext autoreload \n",
    "  %autoreload 2\n",
    "  def show_image(img_path,size=None,ratio=None):\n",
    "      img = colab_utils.image_resize(img_path, size)\n",
    "      cv2_imshow(img)\n",
    "  print('finished!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(\"/pyprobml/book1/figures/images/Figure_15.10.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 15.11:<a name='15.11'></a> <a name='LSTM'></a> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "  Illustration of an LSTM. Adapted from Figure 9.2.4 of <a href='#dive'>[Zha+20]</a> . "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Click me to run setup { display-mode: \"form\" }\n",
    "try:\n",
    "  if PYPROBML_SETUP_ALREADY_RUN:\n",
    "    print('skipping setup')\n",
    "except:\n",
    "  PYPROBML_SETUP_ALREADY_RUN = True\n",
    "  print('running setup...')\n",
    "  !git clone https://github.com/probml/pyprobml /pyprobml &> /dev/null \n",
    "  %cd -q /pyprobml/scripts\n",
    "  import pyprobml_utils as pml\n",
    "  import colab_utils\n",
    "  import os\n",
    "  os.environ[\"PYPROBML\"] = \"..\" # one above current scripts directory\n",
    "  import google.colab \n",
    "  from google.colab.patches import cv2_imshow\n",
    "  %reload_ext autoreload \n",
    "  %autoreload 2\n",
    "  def show_image(img_path,size=None,ratio=None):\n",
    "      img = colab_utils.image_resize(img_path, size)\n",
    "      cv2_imshow(img)\n",
    "  print('finished!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(\"/pyprobml/book1/figures/images/Figure_15.11.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 15.12:<a name='15.12'></a> <a name='stsProb'></a> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "  Conditional probabilities of generating each token at each step for two different sequences. From Figures 9.8.1--9.8.2 of <a href='#dive'>[Zha+20]</a> . Used with kind permission of Aston Zhang. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Click me to run setup { display-mode: \"form\" }\n",
    "try:\n",
    "  if PYPROBML_SETUP_ALREADY_RUN:\n",
    "    print('skipping setup')\n",
    "except:\n",
    "  PYPROBML_SETUP_ALREADY_RUN = True\n",
    "  print('running setup...')\n",
    "  !git clone https://github.com/probml/pyprobml /pyprobml &> /dev/null \n",
    "  %cd -q /pyprobml/scripts\n",
    "  import pyprobml_utils as pml\n",
    "  import colab_utils\n",
    "  import os\n",
    "  os.environ[\"PYPROBML\"] = \"..\" # one above current scripts directory\n",
    "  import google.colab \n",
    "  from google.colab.patches import cv2_imshow\n",
    "  %reload_ext autoreload \n",
    "  %autoreload 2\n",
    "  def show_image(img_path,size=None,ratio=None):\n",
    "      img = colab_utils.image_resize(img_path, size)\n",
    "      cv2_imshow(img)\n",
    "  print('finished!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(\"/pyprobml/book1/figures/images/Figure_15.12_A.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(\"/pyprobml/book1/figures/images/Figure_15.12_B.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 15.13:<a name='15.13'></a> <a name='beamSearch'></a> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "  Illustration of beam search using a beam of size $K=2$. The vocabulary is $\\mathcal  Y = \\ A,B,C,D,E\\ $, with size $V=5$. We assume the top 2 symbols at step 1 are A,C. At step 2, we evaluate $p(y_1=A,y_2=y)$ and $p(y_1=C,y_2=y)$ for each $y \\in \\mathcal  Y $. This takes $O(K V)$ time. We then pick the top 2 partial paths, which are $(y_1=A,y_2=B)$ and $(y_1=C,y_2=E)$, and continue in the obvious way. Adapted from Figure 9.8.3 of <a href='#dive'>[Zha+20]</a> . "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Click me to run setup { display-mode: \"form\" }\n",
    "try:\n",
    "  if PYPROBML_SETUP_ALREADY_RUN:\n",
    "    print('skipping setup')\n",
    "except:\n",
    "  PYPROBML_SETUP_ALREADY_RUN = True\n",
    "  print('running setup...')\n",
    "  !git clone https://github.com/probml/pyprobml /pyprobml &> /dev/null \n",
    "  %cd -q /pyprobml/scripts\n",
    "  import pyprobml_utils as pml\n",
    "  import colab_utils\n",
    "  import os\n",
    "  os.environ[\"PYPROBML\"] = \"..\" # one above current scripts directory\n",
    "  import google.colab \n",
    "  from google.colab.patches import cv2_imshow\n",
    "  %reload_ext autoreload \n",
    "  %autoreload 2\n",
    "  def show_image(img_path,size=None,ratio=None):\n",
    "      img = colab_utils.image_resize(img_path, size)\n",
    "      cv2_imshow(img)\n",
    "  print('finished!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(\"/pyprobml/book1/figures/images/Figure_15.13.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 15.14:<a name='15.14'></a> <a name='textCNN'></a> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "  Illustration of the TextCNN model for binary sentiment classification. Adapted from Figure 15.3.5 of <a href='#dive'>[Zha+20]</a> . "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Click me to run setup { display-mode: \"form\" }\n",
    "try:\n",
    "  if PYPROBML_SETUP_ALREADY_RUN:\n",
    "    print('skipping setup')\n",
    "except:\n",
    "  PYPROBML_SETUP_ALREADY_RUN = True\n",
    "  print('running setup...')\n",
    "  !git clone https://github.com/probml/pyprobml /pyprobml &> /dev/null \n",
    "  %cd -q /pyprobml/scripts\n",
    "  import pyprobml_utils as pml\n",
    "  import colab_utils\n",
    "  import os\n",
    "  os.environ[\"PYPROBML\"] = \"..\" # one above current scripts directory\n",
    "  import google.colab \n",
    "  from google.colab.patches import cv2_imshow\n",
    "  %reload_ext autoreload \n",
    "  %autoreload 2\n",
    "  def show_image(img_path,size=None,ratio=None):\n",
    "      img = colab_utils.image_resize(img_path, size)\n",
    "      cv2_imshow(img)\n",
    "  print('finished!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(\"/pyprobml/book1/figures/images/Figure_15.14.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 15.15:<a name='15.15'></a> <a name='wavenet'></a> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "  Illustration of the wavenet model using dilated (atrous) convolutions, with dilation factors of 1, 2, 4 and 8. From Figure 3 of <a href='#wavenet'>[Aar+16]</a> . Used with kind permission of Aaron van den Oord. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Click me to run setup { display-mode: \"form\" }\n",
    "try:\n",
    "  if PYPROBML_SETUP_ALREADY_RUN:\n",
    "    print('skipping setup')\n",
    "except:\n",
    "  PYPROBML_SETUP_ALREADY_RUN = True\n",
    "  print('running setup...')\n",
    "  !git clone https://github.com/probml/pyprobml /pyprobml &> /dev/null \n",
    "  %cd -q /pyprobml/scripts\n",
    "  import pyprobml_utils as pml\n",
    "  import colab_utils\n",
    "  import os\n",
    "  os.environ[\"PYPROBML\"] = \"..\" # one above current scripts directory\n",
    "  import google.colab \n",
    "  from google.colab.patches import cv2_imshow\n",
    "  %reload_ext autoreload \n",
    "  %autoreload 2\n",
    "  def show_image(img_path,size=None,ratio=None):\n",
    "      img = colab_utils.image_resize(img_path, size)\n",
    "      cv2_imshow(img)\n",
    "  print('finished!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(\"/pyprobml/book1/figures/images/Figure_15.15.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 15.16:<a name='15.16'></a> <a name='attention'></a> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "  Attention computes a weighted average of a set of values, where the weights are derived by comparing the query vector to a set of keys. From Figure 10.3.1 of <a href='#dive'>[Zha+20]</a> . Used with kind permission of Aston Zhang. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Click me to run setup { display-mode: \"form\" }\n",
    "try:\n",
    "  if PYPROBML_SETUP_ALREADY_RUN:\n",
    "    print('skipping setup')\n",
    "except:\n",
    "  PYPROBML_SETUP_ALREADY_RUN = True\n",
    "  print('running setup...')\n",
    "  !git clone https://github.com/probml/pyprobml /pyprobml &> /dev/null \n",
    "  %cd -q /pyprobml/scripts\n",
    "  import pyprobml_utils as pml\n",
    "  import colab_utils\n",
    "  import os\n",
    "  os.environ[\"PYPROBML\"] = \"..\" # one above current scripts directory\n",
    "  import google.colab \n",
    "  from google.colab.patches import cv2_imshow\n",
    "  %reload_ext autoreload \n",
    "  %autoreload 2\n",
    "  def show_image(img_path,size=None,ratio=None):\n",
    "      img = colab_utils.image_resize(img_path, size)\n",
    "      cv2_imshow(img)\n",
    "  print('finished!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(\"/pyprobml/book1/figures/images/Figure_15.16.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 15.17:<a name='15.17'></a> <a name='attenRegression'></a> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "  Kernel regression in 1d. (a) Kernel weight matrix. (b) Resulting predictions on a dense grid of test points. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To reproduce this figure, click the open in colab button: <a href=\"https://colab.research.google.com/github/https://colab.research.google.com/github/probml/pyprobml/blob/master/notebooks/kernel_regression_attention.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Click me to run setup { display-mode: \"form\" }\n",
    "try:\n",
    "  if PYPROBML_SETUP_ALREADY_RUN:\n",
    "    print('skipping setup')\n",
    "except:\n",
    "  PYPROBML_SETUP_ALREADY_RUN = True\n",
    "  print('running setup...')\n",
    "  !git clone https://github.com/probml/pyprobml /pyprobml &> /dev/null \n",
    "  %cd -q /pyprobml/scripts\n",
    "  import pyprobml_utils as pml\n",
    "  import colab_utils\n",
    "  import os\n",
    "  os.environ[\"PYPROBML\"] = \"..\" # one above current scripts directory\n",
    "  import google.colab \n",
    "  from google.colab.patches import cv2_imshow\n",
    "  %reload_ext autoreload \n",
    "  %autoreload 2\n",
    "  def show_image(img_path,size=None,ratio=None):\n",
    "      img = colab_utils.image_resize(img_path, size)\n",
    "      cv2_imshow(img)\n",
    "  print('finished!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(\"/pyprobml/book1/figures/images/Figure_15.17_A.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(\"/pyprobml/book1/figures/images/Figure_15.17_B.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 15.18:<a name='15.18'></a> <a name='seq2seqAttn'></a> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "  Illustration of seq2seq with attention for English to French translation. Used with kind permission of Minh-Thang Luong. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Click me to run setup { display-mode: \"form\" }\n",
    "try:\n",
    "  if PYPROBML_SETUP_ALREADY_RUN:\n",
    "    print('skipping setup')\n",
    "except:\n",
    "  PYPROBML_SETUP_ALREADY_RUN = True\n",
    "  print('running setup...')\n",
    "  !git clone https://github.com/probml/pyprobml /pyprobml &> /dev/null \n",
    "  %cd -q /pyprobml/scripts\n",
    "  import pyprobml_utils as pml\n",
    "  import colab_utils\n",
    "  import os\n",
    "  os.environ[\"PYPROBML\"] = \"..\" # one above current scripts directory\n",
    "  import google.colab \n",
    "  from google.colab.patches import cv2_imshow\n",
    "  %reload_ext autoreload \n",
    "  %autoreload 2\n",
    "  def show_image(img_path,size=None,ratio=None):\n",
    "      img = colab_utils.image_resize(img_path, size)\n",
    "      cv2_imshow(img)\n",
    "  print('finished!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(\"/pyprobml/book1/figures/images/Figure_15.18.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 15.19:<a name='15.19'></a> <a name='translationHeatmap'></a> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "  Illustration of the attention heatmaps generated while translating two sentences from Spanish to English. (a) Input is ``hace mucho frio aqui.'', output is ``it is very cold here.''. (b) Input is ``Â¿todavia estan en casa?'', output is ``are you still at home?''. Note that when generating the output token ``home'', the model should attend to the input token ``casa'', but in fact it seems to attend to the input token ``?''. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Click me to run setup { display-mode: \"form\" }\n",
    "try:\n",
    "  if PYPROBML_SETUP_ALREADY_RUN:\n",
    "    print('skipping setup')\n",
    "except:\n",
    "  PYPROBML_SETUP_ALREADY_RUN = True\n",
    "  print('running setup...')\n",
    "  !git clone https://github.com/probml/pyprobml /pyprobml &> /dev/null \n",
    "  %cd -q /pyprobml/scripts\n",
    "  import pyprobml_utils as pml\n",
    "  import colab_utils\n",
    "  import os\n",
    "  os.environ[\"PYPROBML\"] = \"..\" # one above current scripts directory\n",
    "  import google.colab \n",
    "  from google.colab.patches import cv2_imshow\n",
    "  %reload_ext autoreload \n",
    "  %autoreload 2\n",
    "  def show_image(img_path,size=None,ratio=None):\n",
    "      img = colab_utils.image_resize(img_path, size)\n",
    "      cv2_imshow(img)\n",
    "  print('finished!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(\"/pyprobml/book1/figures/images/Figure_15.19_A.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(\"/pyprobml/book1/figures/images/Figure_15.19_B.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 15.20:<a name='15.20'></a> <a name='EHR'></a> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "  Example of an electronic health record. In this example, 24h after admission to the hospital, the RNN classifier predicts the risk of death as 19.9\\%; the patient ultimately died 10 days after admission. The ``relevant'' keywords from the input clinical notes are shown in red, as identified by an attention mechanism. From Figure 3 of <a href='#Rajkomar2018'>[Alv+18]</a> . Used with kind permission of Alvin Rakomar. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Click me to run setup { display-mode: \"form\" }\n",
    "try:\n",
    "  if PYPROBML_SETUP_ALREADY_RUN:\n",
    "    print('skipping setup')\n",
    "except:\n",
    "  PYPROBML_SETUP_ALREADY_RUN = True\n",
    "  print('running setup...')\n",
    "  !git clone https://github.com/probml/pyprobml /pyprobml &> /dev/null \n",
    "  %cd -q /pyprobml/scripts\n",
    "  import pyprobml_utils as pml\n",
    "  import colab_utils\n",
    "  import os\n",
    "  os.environ[\"PYPROBML\"] = \"..\" # one above current scripts directory\n",
    "  import google.colab \n",
    "  from google.colab.patches import cv2_imshow\n",
    "  %reload_ext autoreload \n",
    "  %autoreload 2\n",
    "  def show_image(img_path,size=None,ratio=None):\n",
    "      img = colab_utils.image_resize(img_path, size)\n",
    "      cv2_imshow(img)\n",
    "  print('finished!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(\"/pyprobml/book1/figures/images/Figure_15.20.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 15.21:<a name='15.21'></a> <a name='SNLI'></a> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "  Illustration of sentence pair entailment classification using an MLP with attention to align the premise (``I do need sleep'') with the hypothesis (``I am tired''). White squares denote active attention weights, blue squares are inactive. (We are assuming hard 0/1 attention for simplicity.) From Figure 15.5.2 of <a href='#dive'>[Zha+20]</a> . Used with kind permission of Aston Zhang. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Click me to run setup { display-mode: \"form\" }\n",
    "try:\n",
    "  if PYPROBML_SETUP_ALREADY_RUN:\n",
    "    print('skipping setup')\n",
    "except:\n",
    "  PYPROBML_SETUP_ALREADY_RUN = True\n",
    "  print('running setup...')\n",
    "  !git clone https://github.com/probml/pyprobml /pyprobml &> /dev/null \n",
    "  %cd -q /pyprobml/scripts\n",
    "  import pyprobml_utils as pml\n",
    "  import colab_utils\n",
    "  import os\n",
    "  os.environ[\"PYPROBML\"] = \"..\" # one above current scripts directory\n",
    "  import google.colab \n",
    "  from google.colab.patches import cv2_imshow\n",
    "  %reload_ext autoreload \n",
    "  %autoreload 2\n",
    "  def show_image(img_path,size=None,ratio=None):\n",
    "      img = colab_utils.image_resize(img_path, size)\n",
    "      cv2_imshow(img)\n",
    "  print('finished!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(\"/pyprobml/book1/figures/images/Figure_15.21.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 15.22:<a name='15.22'></a> <a name='showAttendTell'></a> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "  Image captioning using attention. (a) Soft attention. Generates ``a woman is throwing a frisbee in a park''. (b) Hard attention. Generates ``a man and a woman playing frisbee in a field''. From Figure 6 of <a href='#showAttendTell'>[Kel+15]</a> . Used with kind permission of Kelvin Xu. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Click me to run setup { display-mode: \"form\" }\n",
    "try:\n",
    "  if PYPROBML_SETUP_ALREADY_RUN:\n",
    "    print('skipping setup')\n",
    "except:\n",
    "  PYPROBML_SETUP_ALREADY_RUN = True\n",
    "  print('running setup...')\n",
    "  !git clone https://github.com/probml/pyprobml /pyprobml &> /dev/null \n",
    "  %cd -q /pyprobml/scripts\n",
    "  import pyprobml_utils as pml\n",
    "  import colab_utils\n",
    "  import os\n",
    "  os.environ[\"PYPROBML\"] = \"..\" # one above current scripts directory\n",
    "  import google.colab \n",
    "  from google.colab.patches import cv2_imshow\n",
    "  %reload_ext autoreload \n",
    "  %autoreload 2\n",
    "  def show_image(img_path,size=None,ratio=None):\n",
    "      img = colab_utils.image_resize(img_path, size)\n",
    "      cv2_imshow(img)\n",
    "  print('finished!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(\"/pyprobml/book1/figures/images/Figure_15.22_A.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(\"/pyprobml/book1/figures/images/Figure_15.22_B.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 15.23:<a name='15.23'></a> <a name='transformerTranslation'></a> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "  Illustration of how encoder self-attention for the word ``it'' differs depending on the input context. From   https://ai.googleblog.com/2017/08/transformer-novel-neural-network.html . Used with kind permission of Jakob Uszkoreit. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Click me to run setup { display-mode: \"form\" }\n",
    "try:\n",
    "  if PYPROBML_SETUP_ALREADY_RUN:\n",
    "    print('skipping setup')\n",
    "except:\n",
    "  PYPROBML_SETUP_ALREADY_RUN = True\n",
    "  print('running setup...')\n",
    "  !git clone https://github.com/probml/pyprobml /pyprobml &> /dev/null \n",
    "  %cd -q /pyprobml/scripts\n",
    "  import pyprobml_utils as pml\n",
    "  import colab_utils\n",
    "  import os\n",
    "  os.environ[\"PYPROBML\"] = \"..\" # one above current scripts directory\n",
    "  import google.colab \n",
    "  from google.colab.patches import cv2_imshow\n",
    "  %reload_ext autoreload \n",
    "  %autoreload 2\n",
    "  def show_image(img_path,size=None,ratio=None):\n",
    "      img = colab_utils.image_resize(img_path, size)\n",
    "      cv2_imshow(img)\n",
    "  print('finished!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(\"/pyprobml/book1/figures/images/Figure_15.23.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 15.24:<a name='15.24'></a> <a name='multiHeadAttn'></a> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "  Multi-head attention. Adapted from Figure 9.3.3 of <a href='#dive'>[Zha+20]</a> . "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Click me to run setup { display-mode: \"form\" }\n",
    "try:\n",
    "  if PYPROBML_SETUP_ALREADY_RUN:\n",
    "    print('skipping setup')\n",
    "except:\n",
    "  PYPROBML_SETUP_ALREADY_RUN = True\n",
    "  print('running setup...')\n",
    "  !git clone https://github.com/probml/pyprobml /pyprobml &> /dev/null \n",
    "  %cd -q /pyprobml/scripts\n",
    "  import pyprobml_utils as pml\n",
    "  import colab_utils\n",
    "  import os\n",
    "  os.environ[\"PYPROBML\"] = \"..\" # one above current scripts directory\n",
    "  import google.colab \n",
    "  from google.colab.patches import cv2_imshow\n",
    "  %reload_ext autoreload \n",
    "  %autoreload 2\n",
    "  def show_image(img_path,size=None,ratio=None):\n",
    "      img = colab_utils.image_resize(img_path, size)\n",
    "      cv2_imshow(img)\n",
    "  print('finished!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(\"/pyprobml/book1/figures/images/Figure_15.24.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 15.25:<a name='15.25'></a> <a name='positionalEncodingSinusoids'></a> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "  (a) Positional encoding matrix for a sequence of length $n=60$ and an embedding dimension of size $d=32$. (b) Basis functions for columsn 6 to 9. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To reproduce this figure, click the open in colab button: <a href=\"https://colab.research.google.com/github/https://colab.research.google.com/github/probml/pyprobml/blob/master/notebooks/positional_encoding.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Click me to run setup { display-mode: \"form\" }\n",
    "try:\n",
    "  if PYPROBML_SETUP_ALREADY_RUN:\n",
    "    print('skipping setup')\n",
    "except:\n",
    "  PYPROBML_SETUP_ALREADY_RUN = True\n",
    "  print('running setup...')\n",
    "  !git clone https://github.com/probml/pyprobml /pyprobml &> /dev/null \n",
    "  %cd -q /pyprobml/scripts\n",
    "  import pyprobml_utils as pml\n",
    "  import colab_utils\n",
    "  import os\n",
    "  os.environ[\"PYPROBML\"] = \"..\" # one above current scripts directory\n",
    "  import google.colab \n",
    "  from google.colab.patches import cv2_imshow\n",
    "  %reload_ext autoreload \n",
    "  %autoreload 2\n",
    "  def show_image(img_path,size=None,ratio=None):\n",
    "      img = colab_utils.image_resize(img_path, size)\n",
    "      cv2_imshow(img)\n",
    "  print('finished!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(\"/pyprobml/book1/figures/images/Figure_15.25_A.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(\"/pyprobml/book1/figures/images/Figure_15.25_B.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 15.26:<a name='15.26'></a> <a name='transformer'></a> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "  The transformer. From <a href='#Weng2018attention'>[Lil18]</a> . Used with kind permission of Lilian Weng. Adapted from Figures 1--2 of <a href='#Vaswani2017'>[Ash+17]</a> . "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Click me to run setup { display-mode: \"form\" }\n",
    "try:\n",
    "  if PYPROBML_SETUP_ALREADY_RUN:\n",
    "    print('skipping setup')\n",
    "except:\n",
    "  PYPROBML_SETUP_ALREADY_RUN = True\n",
    "  print('running setup...')\n",
    "  !git clone https://github.com/probml/pyprobml /pyprobml &> /dev/null \n",
    "  %cd -q /pyprobml/scripts\n",
    "  import pyprobml_utils as pml\n",
    "  import colab_utils\n",
    "  import os\n",
    "  os.environ[\"PYPROBML\"] = \"..\" # one above current scripts directory\n",
    "  import google.colab \n",
    "  from google.colab.patches import cv2_imshow\n",
    "  %reload_ext autoreload \n",
    "  %autoreload 2\n",
    "  def show_image(img_path,size=None,ratio=None):\n",
    "      img = colab_utils.image_resize(img_path, size)\n",
    "      cv2_imshow(img)\n",
    "  print('finished!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(\"/pyprobml/book1/figures/images/Figure_15.26.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 15.27:<a name='15.27'></a> <a name='attentionBakeoff'></a> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "  Comparison of (1d) CNNs, RNNs and self-attention models. From Figure 10.6.1 of <a href='#dive'>[Zha+20]</a> . Used with kind permission of Aston Zhang. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Click me to run setup { display-mode: \"form\" }\n",
    "try:\n",
    "  if PYPROBML_SETUP_ALREADY_RUN:\n",
    "    print('skipping setup')\n",
    "except:\n",
    "  PYPROBML_SETUP_ALREADY_RUN = True\n",
    "  print('running setup...')\n",
    "  !git clone https://github.com/probml/pyprobml /pyprobml &> /dev/null \n",
    "  %cd -q /pyprobml/scripts\n",
    "  import pyprobml_utils as pml\n",
    "  import colab_utils\n",
    "  import os\n",
    "  os.environ[\"PYPROBML\"] = \"..\" # one above current scripts directory\n",
    "  import google.colab \n",
    "  from google.colab.patches import cv2_imshow\n",
    "  %reload_ext autoreload \n",
    "  %autoreload 2\n",
    "  def show_image(img_path,size=None,ratio=None):\n",
    "      img = colab_utils.image_resize(img_path, size)\n",
    "      cv2_imshow(img)\n",
    "  print('finished!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(\"/pyprobml/book1/figures/images/Figure_15.27.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 15.28:<a name='15.28'></a> <a name='VIT'></a> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "  The Vision Transformer (ViT) model. This treats an image as a set of input patches. The input is prepended with the special CLASS embedding vector (denoted by *) in location 0. The class label for the image is derived by applying softmax to the final ouput encoding at location 0. From Figure 1 of <a href='#ViT'>[Ale+21]</a> . Used with kind permission of Alexey Dosovitskiy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Click me to run setup { display-mode: \"form\" }\n",
    "try:\n",
    "  if PYPROBML_SETUP_ALREADY_RUN:\n",
    "    print('skipping setup')\n",
    "except:\n",
    "  PYPROBML_SETUP_ALREADY_RUN = True\n",
    "  print('running setup...')\n",
    "  !git clone https://github.com/probml/pyprobml /pyprobml &> /dev/null \n",
    "  %cd -q /pyprobml/scripts\n",
    "  import pyprobml_utils as pml\n",
    "  import colab_utils\n",
    "  import os\n",
    "  os.environ[\"PYPROBML\"] = \"..\" # one above current scripts directory\n",
    "  import google.colab \n",
    "  from google.colab.patches import cv2_imshow\n",
    "  %reload_ext autoreload \n",
    "  %autoreload 2\n",
    "  def show_image(img_path,size=None,ratio=None):\n",
    "      img = colab_utils.image_resize(img_path, size)\n",
    "      cv2_imshow(img)\n",
    "  print('finished!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(\"/pyprobml/book1/figures/images/Figure_15.28.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 15.29:<a name='15.29'></a> <a name='transformers_taxonomy'></a> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "  Venn diagram presenting the taxonomy of different efficient transformer architectures. From <a href='#Tay2020transformers'>[Yi+20]</a> . Used with kind permission of Yi Tay. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Click me to run setup { display-mode: \"form\" }\n",
    "try:\n",
    "  if PYPROBML_SETUP_ALREADY_RUN:\n",
    "    print('skipping setup')\n",
    "except:\n",
    "  PYPROBML_SETUP_ALREADY_RUN = True\n",
    "  print('running setup...')\n",
    "  !git clone https://github.com/probml/pyprobml /pyprobml &> /dev/null \n",
    "  %cd -q /pyprobml/scripts\n",
    "  import pyprobml_utils as pml\n",
    "  import colab_utils\n",
    "  import os\n",
    "  os.environ[\"PYPROBML\"] = \"..\" # one above current scripts directory\n",
    "  import google.colab \n",
    "  from google.colab.patches import cv2_imshow\n",
    "  %reload_ext autoreload \n",
    "  %autoreload 2\n",
    "  def show_image(img_path,size=None,ratio=None):\n",
    "      img = colab_utils.image_resize(img_path, size)\n",
    "      cv2_imshow(img)\n",
    "  print('finished!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(\"/pyprobml/book1/figures/images/Figure_15.29.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 15.30:<a name='15.30'></a> <a name='rand_for_fast_atten'></a> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "  Attention matrix $\\mathbf  A $ rewritten as a product of two lower rank matrices $\\mathbf  Q ^ \\prime  $ and $(\\mathbf  K ^ \\prime  )^ \\top  $ with random feature maps $\\boldsymbol  \\phi  (\\mathbf  q _i) \\in \\mathbb  R ^M$ and $\\boldsymbol  \\phi  (\\mathbf  v _k) \\in \\mathbb  R ^M$ for the corresponding queries/keys stored in the rows/columns. Used with kind permission of Krzysztof Choromanski. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Click me to run setup { display-mode: \"form\" }\n",
    "try:\n",
    "  if PYPROBML_SETUP_ALREADY_RUN:\n",
    "    print('skipping setup')\n",
    "except:\n",
    "  PYPROBML_SETUP_ALREADY_RUN = True\n",
    "  print('running setup...')\n",
    "  !git clone https://github.com/probml/pyprobml /pyprobml &> /dev/null \n",
    "  %cd -q /pyprobml/scripts\n",
    "  import pyprobml_utils as pml\n",
    "  import colab_utils\n",
    "  import os\n",
    "  os.environ[\"PYPROBML\"] = \"..\" # one above current scripts directory\n",
    "  import google.colab \n",
    "  from google.colab.patches import cv2_imshow\n",
    "  %reload_ext autoreload \n",
    "  %autoreload 2\n",
    "  def show_image(img_path,size=None,ratio=None):\n",
    "      img = colab_utils.image_resize(img_path, size)\n",
    "      cv2_imshow(img)\n",
    "  print('finished!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(\"/pyprobml/book1/figures/images/Figure_15.30.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 15.31:<a name='15.31'></a> <a name='fatten'></a> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "  Decomposition of the attention matrix $\\mathbf  A $ can be leveraged to improve attention computations via matrix associativity property. To compute $\\mathbf  AV $, we first calculate $\\mathbf  G =(\\mathbf  k ^ \\prime  )^ \\top  \\mathbf  V $ and then $\\mathbf  q ^ \\prime  \\mathbf  G $, resulting in linear in $N$ space and time complexity. Used with kind permission of Krzysztof Choromanski. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Click me to run setup { display-mode: \"form\" }\n",
    "try:\n",
    "  if PYPROBML_SETUP_ALREADY_RUN:\n",
    "    print('skipping setup')\n",
    "except:\n",
    "  PYPROBML_SETUP_ALREADY_RUN = True\n",
    "  print('running setup...')\n",
    "  !git clone https://github.com/probml/pyprobml /pyprobml &> /dev/null \n",
    "  %cd -q /pyprobml/scripts\n",
    "  import pyprobml_utils as pml\n",
    "  import colab_utils\n",
    "  import os\n",
    "  os.environ[\"PYPROBML\"] = \"..\" # one above current scripts directory\n",
    "  import google.colab \n",
    "  from google.colab.patches import cv2_imshow\n",
    "  %reload_ext autoreload \n",
    "  %autoreload 2\n",
    "  def show_image(img_path,size=None,ratio=None):\n",
    "      img = colab_utils.image_resize(img_path, size)\n",
    "      cv2_imshow(img)\n",
    "  print('finished!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(\"/pyprobml/book1/figures/images/Figure_15.31.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 15.32:<a name='15.32'></a> <a name='elmo'></a> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "  Illustration of ELMo bidrectional language model. Here $y_t=x_ t+1 $ when acting as the target for the forwards LSTM, and $y_t = x_ t-1 $ for the backwards LSTM. (We add \\text  \\em  bos  \\xspace and \\text  \\em  eos  \\xspace sentinels to handle the edge cases.) From <a href='#Weng2019LM'>[Lil19]</a> . Used with kind permission of Lilian Weng. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Click me to run setup { display-mode: \"form\" }\n",
    "try:\n",
    "  if PYPROBML_SETUP_ALREADY_RUN:\n",
    "    print('skipping setup')\n",
    "except:\n",
    "  PYPROBML_SETUP_ALREADY_RUN = True\n",
    "  print('running setup...')\n",
    "  !git clone https://github.com/probml/pyprobml /pyprobml &> /dev/null \n",
    "  %cd -q /pyprobml/scripts\n",
    "  import pyprobml_utils as pml\n",
    "  import colab_utils\n",
    "  import os\n",
    "  os.environ[\"PYPROBML\"] = \"..\" # one above current scripts directory\n",
    "  import google.colab \n",
    "  from google.colab.patches import cv2_imshow\n",
    "  %reload_ext autoreload \n",
    "  %autoreload 2\n",
    "  def show_image(img_path,size=None,ratio=None):\n",
    "      img = colab_utils.image_resize(img_path, size)\n",
    "      cv2_imshow(img)\n",
    "  print('finished!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(\"/pyprobml/book1/figures/images/Figure_15.32.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 15.33:<a name='15.33'></a> <a name='GPT'></a> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "  Illustration of (a) BERT and (b) GPT. $E_t$ is the embedding vector for the input token at location $t$, and $T_t$ is the output target to be predicted. From Figure 3 of <a href='#bert'>[Jac+19]</a> . Used with kind permission of Ming-Wei Chang. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Click me to run setup { display-mode: \"form\" }\n",
    "try:\n",
    "  if PYPROBML_SETUP_ALREADY_RUN:\n",
    "    print('skipping setup')\n",
    "except:\n",
    "  PYPROBML_SETUP_ALREADY_RUN = True\n",
    "  print('running setup...')\n",
    "  !git clone https://github.com/probml/pyprobml /pyprobml &> /dev/null \n",
    "  %cd -q /pyprobml/scripts\n",
    "  import pyprobml_utils as pml\n",
    "  import colab_utils\n",
    "  import os\n",
    "  os.environ[\"PYPROBML\"] = \"..\" # one above current scripts directory\n",
    "  import google.colab \n",
    "  from google.colab.patches import cv2_imshow\n",
    "  %reload_ext autoreload \n",
    "  %autoreload 2\n",
    "  def show_image(img_path,size=None,ratio=None):\n",
    "      img = colab_utils.image_resize(img_path, size)\n",
    "      cv2_imshow(img)\n",
    "  print('finished!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(\"/pyprobml/book1/figures/images/Figure_15.33_A.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(\"/pyprobml/book1/figures/images/Figure_15.33_B.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 15.34:<a name='15.34'></a> <a name='bertEmbedding'></a> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "  Illustration of how a pair of input sequences, denoted A and B, are encoded before feeding to BERT. From Figure 14.8.2 of <a href='#dive'>[Zha+20]</a> . Used with kind permission of Aston Zhang. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Click me to run setup { display-mode: \"form\" }\n",
    "try:\n",
    "  if PYPROBML_SETUP_ALREADY_RUN:\n",
    "    print('skipping setup')\n",
    "except:\n",
    "  PYPROBML_SETUP_ALREADY_RUN = True\n",
    "  print('running setup...')\n",
    "  !git clone https://github.com/probml/pyprobml /pyprobml &> /dev/null \n",
    "  %cd -q /pyprobml/scripts\n",
    "  import pyprobml_utils as pml\n",
    "  import colab_utils\n",
    "  import os\n",
    "  os.environ[\"PYPROBML\"] = \"..\" # one above current scripts directory\n",
    "  import google.colab \n",
    "  from google.colab.patches import cv2_imshow\n",
    "  %reload_ext autoreload \n",
    "  %autoreload 2\n",
    "  def show_image(img_path,size=None,ratio=None):\n",
    "      img = colab_utils.image_resize(img_path, size)\n",
    "      cv2_imshow(img)\n",
    "  print('finished!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(\"/pyprobml/book1/figures/images/Figure_15.34.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 15.35:<a name='15.35'></a> <a name='bert-tasks'></a> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "  Illustration of how BERT can be used for different kinds of supervised NLP tasks. (a) Single sentence classification (e.g., sentiment analysis); (b) Sentence-pair classification (e.g., textual entailment); (d) Single sentence tagging (e.g., shallow parsing); (d) Question answering. From Figure 4 of <a href='#bert'>[Jac+19]</a> . Used with kind permission of Ming-Wei Chang. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Click me to run setup { display-mode: \"form\" }\n",
    "try:\n",
    "  if PYPROBML_SETUP_ALREADY_RUN:\n",
    "    print('skipping setup')\n",
    "except:\n",
    "  PYPROBML_SETUP_ALREADY_RUN = True\n",
    "  print('running setup...')\n",
    "  !git clone https://github.com/probml/pyprobml /pyprobml &> /dev/null \n",
    "  %cd -q /pyprobml/scripts\n",
    "  import pyprobml_utils as pml\n",
    "  import colab_utils\n",
    "  import os\n",
    "  os.environ[\"PYPROBML\"] = \"..\" # one above current scripts directory\n",
    "  import google.colab \n",
    "  from google.colab.patches import cv2_imshow\n",
    "  %reload_ext autoreload \n",
    "  %autoreload 2\n",
    "  def show_image(img_path,size=None,ratio=None):\n",
    "      img = colab_utils.image_resize(img_path, size)\n",
    "      cv2_imshow(img)\n",
    "  print('finished!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(\"/pyprobml/book1/figures/images/Figure_15.35_A.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(\"/pyprobml/book1/figures/images/Figure_15.35_B.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(\"/pyprobml/book1/figures/images/Figure_15.35_C.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(\"/pyprobml/book1/figures/images/Figure_15.35_D.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 15.36:<a name='15.36'></a> <a name='T5'></a> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "  Illustration of how the T5 model (``Text-to-text Transfer Transformer'') can be used to perform multiple NLP tasks, such as translating English to German; determining if a sentence is linguistic valid or not ( \\bf CoLA  stands for ``Corpus of Linguistic Acceptability''); determining the degree of semantic similarity ( \\bf STSB  stands for ``Semantic Textual Similarity Benchmark''); and abstractive summarization. From Figure 1 of <a href='#T5'>[Col+19]</a> . Used with kind permission of Colin Raffel. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Click me to run setup { display-mode: \"form\" }\n",
    "try:\n",
    "  if PYPROBML_SETUP_ALREADY_RUN:\n",
    "    print('skipping setup')\n",
    "except:\n",
    "  PYPROBML_SETUP_ALREADY_RUN = True\n",
    "  print('running setup...')\n",
    "  !git clone https://github.com/probml/pyprobml /pyprobml &> /dev/null \n",
    "  %cd -q /pyprobml/scripts\n",
    "  import pyprobml_utils as pml\n",
    "  import colab_utils\n",
    "  import os\n",
    "  os.environ[\"PYPROBML\"] = \"..\" # one above current scripts directory\n",
    "  import google.colab \n",
    "  from google.colab.patches import cv2_imshow\n",
    "  %reload_ext autoreload \n",
    "  %autoreload 2\n",
    "  def show_image(img_path,size=None,ratio=None):\n",
    "      img = colab_utils.image_resize(img_path, size)\n",
    "      cv2_imshow(img)\n",
    "  print('finished!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(\"/pyprobml/book1/figures/images/Figure_15.36.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References:\n",
    " <a name='wavenet'>[Aar+16]</a> V. Aaron, D. Sander, Z. Heiga, S. Karen, V. Oriol, G. Alex, K. Nal, S. Andrew and K. Koray. \"WaveNet: A Generative Model for Raw Audio\". abs/1609.03499 (2016). arXiv: 1609.03499 \n",
    "\n",
    "<a name='ViT'>[Ale+21]</a> D. Alexey, B. Lucas, K. A. Dirk, Z. Xiaohua, U. T. Mostafa, M. Matthias, H. G. Sylvain, U. Jakob and H. Neil. \"An Image is Worth 16x16 Words: Transformers for ImageRecognition at Scale\". (2021). \n",
    "\n",
    "<a name='Rajkomar2018'>[Alv+18]</a> R. Alvin, O. Eyal, C. Kai, D. A. Nissan, H. Michaela, L. PeterJ, L. LiuXiaobing, M. Jake, S. Mimi, S. Patrik, Y. Hector, Z. Kun, Z. Yi, F. Gerardo, D. GavinE, I. Jamie, L. Quoc, L. K. Alexander, T. Justin, W. De, W. James, W. Jimbo, L. Dana, V. L, C. Katherine, P. Michael, M. MadabushiSrinivasan, S. NigamH, B. AtulJ, H. D, C. Claire, C. GregS and D. Jeffrey. \"Scalable and accurate deep learning with electronic healthrecords\". In: NPJ Digit Med (2018). \n",
    "\n",
    "<a name='Vaswani2017'>[Ash+17]</a> V. Ashish, S. Noam, P. Niki, U. Jakob, J. Llion, G. AidanN, K. KaiserLukasz and P. Illia. \"Attention Is All You Need\". (2017). \n",
    "\n",
    "<a name='T5'>[Col+19]</a> R. Colin, S. Noam, R. Adam, L. LeeKatherine, N. Sharan, M. Michael, Z. ZhouYanqi, L. Wei and L. PeterJ. \"Exploring the Limits of Transfer Learning with a UnifiedText-to-Text Transformer\". abs/1910.10683 (2019). arXiv: 1910.10683 \n",
    "\n",
    "<a name='bert'>[Jac+19]</a> D. Jacob, C. Ming-Wei, L. Kenton and T. ToutanovaKristina. \"BERT: Pre-training of Deep Bidirectional Transformers forLanguage Understanding\". (2019). \n",
    "\n",
    "<a name='showAttendTell'>[Kel+15]</a> X. Kelvin, B. JimmyLei, K. Ryan, C. K. Aaron, S. Ruslan, Z. S and B. Yoshua. \"Show, Attend and Tell: Neural Image Caption Generation withVisual Attention\". (2015). \n",
    "\n",
    "<a name='Weng2018attention'>[Lil18]</a> W. Lilian \"Attention? Attention!\". In: lilianweng.github.io/lil-log (2018). \n",
    "\n",
    "<a name='Weng2019LM'>[Lil19]</a> W. Lilian \"Generalized Language Models\". In: lilianweng.github.io/lil-log (2019). \n",
    "\n",
    "<a name='Luong2016thesis'>[Luo16]</a> M. Luong \"Neural machine translation\". (2016). \n",
    "\n",
    "<a name='Tay2020transformers'>[Yi+20]</a> T. Yi, D. Mostafa, B. Dara and M. MetzlerDonald. \"Efficient Transformers: A Survey\". abs/2009.06732 (2020). arXiv: 2009.06732 \n",
    "\n",
    "<a name='dive'>[Zha+20]</a> A. Zhang, Z. Lipton, M. Li and A. Smola. \"Dive into deep learning\". (2020). \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
