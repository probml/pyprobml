{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright 2021 Google LLC\n",
    "# Use of this source code is governed by an MIT-style\n",
    "# license that can be found in the LICENSE file or at\n",
    "# https://opensource.org/licenses/MIT.\n",
    "# Notebook authors: Kevin P. Murphy (murphyk@gmail.com)\n",
    "# and Mahmoud Soliman (mjs@aucegypt.edu)\n",
    "\n",
    "# This notebook reproduces figures for chapter 23 from the book\n",
    "# \"Probabilistic Machine Learning: An Introduction\"\n",
    "# by Kevin Murphy (MIT Press, 2021).\n",
    "# Book pdf is available from http://probml.ai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://opensource.org/licenses/MIT\" target=\"_parent\"><img src=\"https://img.shields.io/github/license/probml/pyprobml\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/probml/pyprobml/blob/master/book1/figures/chapter23_graph_embeddings_figures.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 23.1:<a name='23.1'></a> <a name='non_euclidean_vs_euclidean'></a> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "  An illustration of Euclidean vs. non-Euclidean graphs. Used with permission from \\cite  chami2020machine .\\relax "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Click me to run setup { display-mode: \"form\" }\n",
    "try:\n",
    "  if PYPROBML_SETUP_ALREADY_RUN:\n",
    "    print('skipping setup')\n",
    "except:\n",
    "  PYPROBML_SETUP_ALREADY_RUN = True\n",
    "  print('running setup...')\n",
    "  !git clone https://github.com/probml/pyprobml /pyprobml &> /dev/null \n",
    "  %cd -q /pyprobml/scripts\n",
    "  import pyprobml_utils as pml\n",
    "  import colab_utils\n",
    "  import os\n",
    "  os.environ[\"PYPROBML\"] = \"..\" # one above current scripts directory\n",
    "  import google.colab \n",
    "  from google.colab.patches import cv2_imshow\n",
    "  %reload_ext autoreload \n",
    "  %autoreload 2\n",
    "  def show_image(img_path,size=None,ratio=None):\n",
    "      img = colab_utils.image_resize(img_path, size)\n",
    "      cv2_imshow(img)\n",
    "  print('finished!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(\"/pyprobml/book1/figures/images/Figure_23.1_A.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(\"/pyprobml/book1/figures/images/Figure_23.1_B.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 23.2:<a name='23.2'></a> <a name='enc-dec'></a> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "  Illustration of the \\textsc  GraphEDM  framework from \\citet  chami2020machine . Based on the supervision available, methods will use some or all of the branches. In particular, unsupervised methods do not leverage label decoding for training and only optimize the similarity decoder (lower branch). On the other hand, semi-supervised and supervised methods leverage the additional supervision to learn models' parameters (upper branch). Used with permission.\\relax "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Click me to run setup { display-mode: \"form\" }\n",
    "try:\n",
    "  if PYPROBML_SETUP_ALREADY_RUN:\n",
    "    print('skipping setup')\n",
    "except:\n",
    "  PYPROBML_SETUP_ALREADY_RUN = True\n",
    "  print('running setup...')\n",
    "  !git clone https://github.com/probml/pyprobml /pyprobml &> /dev/null \n",
    "  %cd -q /pyprobml/scripts\n",
    "  import pyprobml_utils as pml\n",
    "  import colab_utils\n",
    "  import os\n",
    "  os.environ[\"PYPROBML\"] = \"..\" # one above current scripts directory\n",
    "  import google.colab \n",
    "  from google.colab.patches import cv2_imshow\n",
    "  %reload_ext autoreload \n",
    "  %autoreload 2\n",
    "  def show_image(img_path,size=None,ratio=None):\n",
    "      img = colab_utils.image_resize(img_path, size)\n",
    "      cv2_imshow(img)\n",
    "  print('finished!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 23.3:<a name='23.3'></a> <a name='shallow'></a> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "  Shallow embedding methods. The encoder is a simple embedding look-up and the graph structure is only used in the loss function. Reprinted with permission from \\cite  chami2020machine .\\relax "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Click me to run setup { display-mode: \"form\" }\n",
    "try:\n",
    "  if PYPROBML_SETUP_ALREADY_RUN:\n",
    "    print('skipping setup')\n",
    "except:\n",
    "  PYPROBML_SETUP_ALREADY_RUN = True\n",
    "  print('running setup...')\n",
    "  !git clone https://github.com/probml/pyprobml /pyprobml &> /dev/null \n",
    "  %cd -q /pyprobml/scripts\n",
    "  import pyprobml_utils as pml\n",
    "  import colab_utils\n",
    "  import os\n",
    "  os.environ[\"PYPROBML\"] = \"..\" # one above current scripts directory\n",
    "  import google.colab \n",
    "  from google.colab.patches import cv2_imshow\n",
    "  %reload_ext autoreload \n",
    "  %autoreload 2\n",
    "  def show_image(img_path,size=None,ratio=None):\n",
    "      img = colab_utils.image_resize(img_path, size)\n",
    "      cv2_imshow(img)\n",
    "  print('finished!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 23.4:<a name='23.4'></a> <a name='walk'></a> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "  An overview of the pipeline for random-walk graph embedding methods. Reprinted with permission from <a href='#godec_2018'>[Pri18]</a> .\\relax "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Click me to run setup { display-mode: \"form\" }\n",
    "try:\n",
    "  if PYPROBML_SETUP_ALREADY_RUN:\n",
    "    print('skipping setup')\n",
    "except:\n",
    "  PYPROBML_SETUP_ALREADY_RUN = True\n",
    "  print('running setup...')\n",
    "  !git clone https://github.com/probml/pyprobml /pyprobml &> /dev/null \n",
    "  %cd -q /pyprobml/scripts\n",
    "  import pyprobml_utils as pml\n",
    "  import colab_utils\n",
    "  import os\n",
    "  os.environ[\"PYPROBML\"] = \"..\" # one above current scripts directory\n",
    "  import google.colab \n",
    "  from google.colab.patches import cv2_imshow\n",
    "  %reload_ext autoreload \n",
    "  %autoreload 2\n",
    "  def show_image(img_path,size=None,ratio=None):\n",
    "      img = colab_utils.image_resize(img_path, size)\n",
    "      cv2_imshow(img)\n",
    "  print('finished!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(\"/pyprobml/book1/figures/images/Figure_23.4.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 23.5:<a name='23.5'></a> <a name='graphSage'></a> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "  Illustration of the GraphSAGE model. Reprinted with permission from <a href='#hamilton2017inductive'>[WZJ17]</a> .\\relax "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Click me to run setup { display-mode: \"form\" }\n",
    "try:\n",
    "  if PYPROBML_SETUP_ALREADY_RUN:\n",
    "    print('skipping setup')\n",
    "except:\n",
    "  PYPROBML_SETUP_ALREADY_RUN = True\n",
    "  print('running setup...')\n",
    "  !git clone https://github.com/probml/pyprobml /pyprobml &> /dev/null \n",
    "  %cd -q /pyprobml/scripts\n",
    "  import pyprobml_utils as pml\n",
    "  import colab_utils\n",
    "  import os\n",
    "  os.environ[\"PYPROBML\"] = \"..\" # one above current scripts directory\n",
    "  import google.colab \n",
    "  from google.colab.patches import cv2_imshow\n",
    "  %reload_ext autoreload \n",
    "  %autoreload 2\n",
    "  def show_image(img_path,size=None,ratio=None):\n",
    "      img = colab_utils.image_resize(img_path, size)\n",
    "      cv2_imshow(img)\n",
    "  print('finished!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(\"/pyprobml/book1/figures/images/Figure_23.5.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 23.6:<a name='23.6'></a> <a name='hgcn_viz'></a> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "  Euclidean (left) and hyperbolic (right) embeddings of a tree graph. Hyperbolic embeddings learn natural hierarchies in the embedding space (depth indicated by color). Reprinted with permission from <a href='#chami2019hyperbolic'>[Ine+19]</a> .\\relax "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Click me to run setup { display-mode: \"form\" }\n",
    "try:\n",
    "  if PYPROBML_SETUP_ALREADY_RUN:\n",
    "    print('skipping setup')\n",
    "except:\n",
    "  PYPROBML_SETUP_ALREADY_RUN = True\n",
    "  print('running setup...')\n",
    "  !git clone https://github.com/probml/pyprobml /pyprobml &> /dev/null \n",
    "  %cd -q /pyprobml/scripts\n",
    "  import pyprobml_utils as pml\n",
    "  import colab_utils\n",
    "  import os\n",
    "  os.environ[\"PYPROBML\"] = \"..\" # one above current scripts directory\n",
    "  import google.colab \n",
    "  from google.colab.patches import cv2_imshow\n",
    "  %reload_ext autoreload \n",
    "  %autoreload 2\n",
    "  def show_image(img_path,size=None,ratio=None):\n",
    "      img = colab_utils.image_resize(img_path, size)\n",
    "      cv2_imshow(img)\n",
    "  print('finished!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(\"/pyprobml/book1/figures/images/Figure_23.6_A.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(\"/pyprobml/book1/figures/images/Figure_23.6_B.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 23.7:<a name='23.7'></a> <a name='agg_unsup'></a> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "  Unsupervised graph neural networks. Graph structure and input features are mapped to low-dimensional embeddings using a graph neural network encoder. Embeddings are then decoded to compute a graph regularization loss (unsupervised). Reprinted with permission from \\cite  chami2020machine .\\relax "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Click me to run setup { display-mode: \"form\" }\n",
    "try:\n",
    "  if PYPROBML_SETUP_ALREADY_RUN:\n",
    "    print('skipping setup')\n",
    "except:\n",
    "  PYPROBML_SETUP_ALREADY_RUN = True\n",
    "  print('running setup...')\n",
    "  !git clone https://github.com/probml/pyprobml /pyprobml &> /dev/null \n",
    "  %cd -q /pyprobml/scripts\n",
    "  import pyprobml_utils as pml\n",
    "  import colab_utils\n",
    "  import os\n",
    "  os.environ[\"PYPROBML\"] = \"..\" # one above current scripts directory\n",
    "  import google.colab \n",
    "  from google.colab.patches import cv2_imshow\n",
    "  %reload_ext autoreload \n",
    "  %autoreload 2\n",
    "  def show_image(img_path,size=None,ratio=None):\n",
    "      img = colab_utils.image_resize(img_path, size)\n",
    "      cv2_imshow(img)\n",
    "  print('finished!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 23.8:<a name='23.8'></a> <a name='fraudGraph'></a> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "  A graph representation of some financial transactions. Adapted from   http://pgql-lang.org/spec/1.2/ . "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Click me to run setup { display-mode: \"form\" }\n",
    "try:\n",
    "  if PYPROBML_SETUP_ALREADY_RUN:\n",
    "    print('skipping setup')\n",
    "except:\n",
    "  PYPROBML_SETUP_ALREADY_RUN = True\n",
    "  print('running setup...')\n",
    "  !git clone https://github.com/probml/pyprobml /pyprobml &> /dev/null \n",
    "  %cd -q /pyprobml/scripts\n",
    "  import pyprobml_utils as pml\n",
    "  import colab_utils\n",
    "  import os\n",
    "  os.environ[\"PYPROBML\"] = \"..\" # one above current scripts directory\n",
    "  import google.colab \n",
    "  from google.colab.patches import cv2_imshow\n",
    "  %reload_ext autoreload \n",
    "  %autoreload 2\n",
    "  def show_image(img_path,size=None,ratio=None):\n",
    "      img = colab_utils.image_resize(img_path, size)\n",
    "      cv2_imshow(img)\n",
    "  print('finished!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(\"/pyprobml/book1/figures/images/Figure_23.8.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 23.9:<a name='23.9'></a> <a name='smell'></a> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "  Structurally similar molecules do not necessarily have similar odor descriptors. (A) Lyral, the reference molecule. (B) Molecules with similar structure can share similar odor descriptors. (C) However, a small structural change can render the molecule odorless. (D) Further, large structural changes can leave the odor of the molecule largely unchanged. From Figure 1 of <a href='#SanchezLengeling2019'>[Ben+19]</a> , originally from <a href='#Ohloff2012'>[GWP12]</a> . Used with kind permission of Benjamin Sanchez-Lengeling. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Click me to run setup { display-mode: \"form\" }\n",
    "try:\n",
    "  if PYPROBML_SETUP_ALREADY_RUN:\n",
    "    print('skipping setup')\n",
    "except:\n",
    "  PYPROBML_SETUP_ALREADY_RUN = True\n",
    "  print('running setup...')\n",
    "  !git clone https://github.com/probml/pyprobml /pyprobml &> /dev/null \n",
    "  %cd -q /pyprobml/scripts\n",
    "  import pyprobml_utils as pml\n",
    "  import colab_utils\n",
    "  import os\n",
    "  os.environ[\"PYPROBML\"] = \"..\" # one above current scripts directory\n",
    "  import google.colab \n",
    "  from google.colab.patches import cv2_imshow\n",
    "  %reload_ext autoreload \n",
    "  %autoreload 2\n",
    "  def show_image(img_path,size=None,ratio=None):\n",
    "      img = colab_utils.image_resize(img_path, size)\n",
    "      cv2_imshow(img)\n",
    "  print('finished!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(\"/pyprobml/book1/figures/images/Figure_23.9.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References:\n",
    " <a name='SanchezLengeling2019'>[Ben+19]</a> S. Benjamin, W. JenniferN, L. K, G. RichardC, A. Al'an and W. AlexanderB. \"Machine Learning for Scent: Learning GeneralizablePerceptual Representations of Small Molecules\". abs/1910.10685 (2019). arXiv: 1910.10685 \n",
    "\n",
    "<a name='Ohloff2012'>[GWP12]</a> O. Gunther, P. Wilhelm and K. Philip. \"Scent and Chemistry\". (2012). \n",
    "\n",
    "<a name='chami2019hyperbolic'>[Ine+19]</a> C. Ines, Y. Zhitao, R. Christopher and L. Jure. \"Hyperbolic graph convolutional neural networks\". (2019). \n",
    "\n",
    "<a name='godec_2018'>[Pri18]</a> G. Primo≈æ \"\". (2018). \n",
    "\n",
    "<a name='hamilton2017inductive'>[WZJ17]</a> H. Will, Y. Zhitao and L. Jure. \"Inductive representation learning on large graphs\". (2017). \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
